{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the same code as before, please solve the following exercises\n",
    "    1. Change the number of observations to 100,000 and see what happens.\n",
    "    2. Play around with the learning rate. Values like 0.0001, 0.001, 0.1, 1 are all interesting to observe. \n",
    "    3. Change the loss function. An alternative loss for regressions is the Huber loss. \n",
    "    The Huber loss is more appropriate than the L2-norm when we have outliers, as it is less sensitive to them (in our example we don't have outliers, but you will surely stumble upon a dataset with outliers in the future). The L2-norm loss puts all differences *to the square*, so outliers have a lot of influence on the outcome. \n",
    "    The proper syntax of the Huber loss is 'huber_loss'\n",
    "    \n",
    "    \n",
    "Useful tip: When you change something, don't forget to RERUN all cells. This can be done easily by clicking:\n",
    "Kernel -> Restart & Run All\n",
    "If you don't do that, your algorithm will keep the OLD values of all parameters.\n",
    "\n",
    "You can either use this file for all the exercises, or check the solutions of EACH ONE of them in the separate files we have provided. All other files are solutions of each problem. If you feel confident enough, you can simply change values in this file. Please note that it will be nice, if you return the file to starting position after you have solved a problem, so you can use the lecture as a basis for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We must always import the relevant libraries for our problem at hand. NumPy and TensorFlow are required for this example.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation\n",
    "\n",
    "We generate data using the exact same logic and code as the example from the previous notebook. The only difference now is that we save it to an npz file. Npz is numpy's file type which allows you to save numpy arrays into a single .npz file. We introduce this change because in machine learning most often: \n",
    "\n",
    "* you are given some data (csv, database, etc.)\n",
    "* you preprocess it into a desired format (later on we will see methods for preprocesing)\n",
    "* you save it into npz files (if you're working in Python) to access later\n",
    "\n",
    "Nothing to worry about - this is literally saving your NumPy arrays into a file that you can later access, nothing more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we should declare a variable containing the size of the training set we want to generate.\n",
    "observations = 10000\n",
    "\n",
    "# We will work with two variables as inputs. You can think about them as x1 and x2 in our previous examples.\n",
    "# We have picked x and z, since it is easier to differentiate them.\n",
    "# We generate them randomly, drawing from an uniform distribution. There are 3 arguments of this method (low, high, size).\n",
    "# The size of xs and zs is observations x 1. In this case: 1000 x 1.\n",
    "xs = np.random.uniform(low=-10, high=10, size=(observations,1))\n",
    "zs = np.random.uniform(-10, 10, (observations,1))\n",
    "\n",
    "# Combine the two dimensions of the input into one input matrix. \n",
    "# This is the X matrix from the linear model y = x*w + b.\n",
    "# column_stack is a Numpy method, which combines two matrices (vectors) into one.\n",
    "generated_inputs = np.column_stack((xs,zs))\n",
    "\n",
    "# We add a random small noise to the function i.e. f(x,z) = 2x - 3z + 5 + <small noise>\n",
    "noise = np.random.uniform(-1, 1, (observations,1))\n",
    "\n",
    "# Produce the targets according to our f(x,z) = 2x - 3z + 5 + noise definition.\n",
    "# In this way, we are basically saying: the weights should be 2 and -3, while the bias is 5.\n",
    "generated_targets = 2*xs - 3*zs + 5 + noise\n",
    "\n",
    "# save into an npz file called \"TF_intro\"\n",
    "np.savez('TF_intro', inputs=generated_inputs, targets=generated_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving with TensorFlow\n",
    "\n",
    "<i/>Note: This intro is just the basics of TensorFlow which has way more capabilities and depth than that.<i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data from the NPZ\n",
    "training_data = np.load('TF_intro.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected float32 passed to parameter 'y' of op 'Equal', got 'auto' of type 'str' instead. Error: Expected float32, got 'auto' of type 'str' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m_AssertCompatible\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m    323\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m     \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    262\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m     _ = [_check_failed(v) for v in nest.flatten(values)\n\u001b[0m\u001b[1;32m    264\u001b[0m          if not isinstance(v, expected_types)]\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    263\u001b[0m     _ = [_check_failed(v) for v in nest.flatten(values)\n\u001b[0;32m--> 264\u001b[0;31m          if not isinstance(v, expected_types)]\n\u001b[0m\u001b[1;32m    265\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m_check_failed\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m    247\u001b[0m   \u001b[0;31m# it is safe to use here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: auto",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    528\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_composite_tensors)\u001b[0m\n\u001b[1;32m   1295\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    285\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    226\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 227\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    264\u001b[0m           \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m           allow_broadcast=allow_broadcast))\n\u001b[0m\u001b[1;32m    266\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m       \u001b[0m_AssertCompatible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m_AssertCompatible\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m    330\u001b[0m       raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n\u001b[0;32m--> 331\u001b[0;31m                       (dtype.name, repr(mismatch), type(mismatch).__name__))\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected float32, got 'auto' of type 'str' instead.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-4e724a55f483>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# so the number of epochs is 'kind of' mandatory, too\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# we can play around with verbose; we prefer verbose=2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'targets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    548\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[1;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2431\u001b[0m     \u001b[0mis_compile_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2432\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2433\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_from_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2434\u001b[0m       \u001b[0mis_compile_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_compile_from_inputs\u001b[0;34m(self, all_inputs, target, orig_inputs, orig_target)\u001b[0m\n\u001b[1;32m   2666\u001b[0m         \u001b[0msample_weight_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_weight_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2667\u001b[0m         \u001b[0mrun_eagerly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2668\u001b[0;31m         experimental_run_tf_function=self._experimental_run_tf_function)\n\u001b[0m\u001b[1;32m   2669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2670\u001b[0m   \u001b[0;31m# TODO(omalleyt): Consider changing to a more descriptive function name.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m       \u001b[0;31m# Creates the model loss and weighted metrics sub-graphs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_weights_loss_and_weighted_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m       \u001b[0;31m# Functions for train, test and predict will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_compile_weights_loss_and_weighted_metrics\u001b[0;34m(self, sample_weights)\u001b[0m\n\u001b[1;32m   1651\u001b[0m       \u001b[0;31m#                   loss_weight_2 * output_2_loss_fn(...) +\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m       \u001b[0;31m#                   layer losses.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1653\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_total_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prepare_skip_target_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_prepare_total_loss\u001b[0;34m(self, masks)\u001b[0m\n\u001b[1;32m   1711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reduction'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1713\u001b[0;31m             \u001b[0mper_sample_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1714\u001b[0m             weighted_losses = losses_utils.compute_weighted_loss(\n\u001b[1;32m   1715\u001b[0m                 \u001b[0mper_sample_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/losses.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    219\u001b[0m       y_pred, y_true = tf_losses_util.squeeze_or_expand_dimensions(\n\u001b[1;32m    220\u001b[0m           y_pred, y_true)\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/losses.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, delta, reduction, name)\u001b[0m\n\u001b[1;32m    757\u001b[0m                name='huber_loss'):\n\u001b[1;32m    758\u001b[0m     super(Huber, self).__init__(\n\u001b[0;32m--> 759\u001b[0;31m         huber_loss, name=name, reduction=reduction, delta=delta)\n\u001b[0m\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/losses.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fn, reduction, name, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m                \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                **kwargs):\n\u001b[0;32m--> 204\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLossFunctionWrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/losses.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, reduction, name)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlosses_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReductionV2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mlosses_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReductionV2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/losses/loss_reduction.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(cls, key)\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid Reduction Key %s.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mtensor_equals\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1334\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincompatible_shape_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m     \u001b[0;31m# In legacy graph mode, tensor equality is object equality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mequal\u001b[0;34m(x, y, incompatible_shape_error, name)\u001b[0m\n\u001b[1;32m   3625\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   3626\u001b[0m         \u001b[0;34m\"Equal\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincompatible_shape_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mincompatible_shape_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3627\u001b[0;31m                  name=name)\n\u001b[0m\u001b[1;32m   3628\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3629\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    534\u001b[0m                   \u001b[0;34m\"type '%s' instead. Error: %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m                   (dtypes.as_dtype(dtype).name, input_arg.name, op_type_name,\n\u001b[0;32m--> 536\u001b[0;31m                    repr(values), type(values).__name__, err))\n\u001b[0m\u001b[1;32m    537\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0;31m# What type does convert_to_tensor think it has?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected float32 passed to parameter 'y' of op 'Equal', got 'auto' of type 'str' instead. Error: Expected float32, got 'auto' of type 'str' instead."
     ]
    }
   ],
   "source": [
    "# Declare a variable where we will store the input size of our model\n",
    "# It should be equal to the number of variables you have\n",
    "input_size = 2\n",
    "# Declare the output size of the model\n",
    "# It should be equal to the number of outputs you've got (for regressions that's usually 1)\n",
    "output_size = 1\n",
    "\n",
    "# Outline the model\n",
    "# We lay out the model in 'Sequential'\n",
    "# Note that there are no calculations involved - we are just describing our network\n",
    "model = tf.keras.Sequential([\n",
    "                            # Each 'layer' is listed here\n",
    "                            # The method 'Dense' indicates, our mathematical operation to be (xw + b)\n",
    "                            tf.keras.layers.Dense(output_size,\n",
    "                                                 # there are extra arguments you can include to customize your model\n",
    "                                                 # in our case we are just trying to create a solution that is \n",
    "                                                 # as close as possible to our NumPy model\n",
    "                                                 kernel_initializer=tf.random_uniform_initializer(minval=-0.1, maxval=0.1),\n",
    "                                                 bias_initializer=tf.random_uniform_initializer(minval=-0.1, maxval=0.1)\n",
    "                                                 )\n",
    "                            ])\n",
    "\n",
    "# We can also define a custom optimizer, where we can specify the learning rate\n",
    "custom_optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "# Note that sometimes you may also need a custom loss function \n",
    "# That's much harder to implement and won't be covered in this course though\n",
    "\n",
    "# 'compile' is the place where you select and indicate the optimizers and the loss\n",
    "model.compile(optimizer=custom_optimizer, loss=tf.keras.losses.Huber)\n",
    "\n",
    "# finally we fit the model, indicating the inputs and targets\n",
    "# if they are not otherwise specified the number of epochs will be 1 (a single epoch of training), \n",
    "# so the number of epochs is 'kind of' mandatory, too\n",
    "# we can play around with verbose; we prefer verbose=2\n",
    "model.fit(training_data['inputs'], training_data['targets'], epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the weights and bias\n",
    "Extracting the weight(s) and bias(es) of a model is not an essential step for the machine learning process. In fact, usually they would not tell us much in a deep learning context. However, this simple example was set up in a way, which allows us to verify if the answers we get are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 2.0017736],\n",
       "        [-3.001283 ]], dtype=float32), array([4.994878], dtype=float32)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the weights and biases is achieved quite easily\n",
    "model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0017736],\n",
       "       [-3.001283 ]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can save the weights and biases in separate variables for easier examination\n",
    "# Note that there can be hundreds or thousands of them!\n",
    "weights = model.layers[0].get_weights()[0]\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.994878], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can save the weights and biases in separate variables for easier examination\n",
    "# Note that there can be hundreds or thousands of them!\n",
    "bias = model.layers[0].get_weights()[1]\n",
    "bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the outputs (make predictions)\n",
    "Once more, this is not an essential step, however, we usually want to be able to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.6],\n",
       "       [-19.9],\n",
       "       [ -7.9],\n",
       "       ...,\n",
       "       [ 19.8],\n",
       "       [ 24.9],\n",
       "       [ -5.3]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can predict new values in order to actually make use of the model\n",
    "# Sometimes it is useful to round the values to be able to read the output\n",
    "# Usually we use this method on NEW DATA, rather than our original training data\n",
    "model.predict_on_batch(training_data['inputs']).numpy().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.1],\n",
       "       [-19.6],\n",
       "       [ -7.5],\n",
       "       ...,\n",
       "       [ 19.3],\n",
       "       [ 25.8],\n",
       "       [ -6.2]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we display our targets (actual observed values), we can manually compare the outputs and the targets\n",
    "training_data['targets'].round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The model is optimized, so the outputs are calculated based on the last form of the model\n",
    "\n",
    "# We have to np.squeeze the arrays in order to fit them to what the plot function expects.\n",
    "# Doesn't change anything as we cut dimensions of size 1 - just a technicality.\n",
    "plt.plot(np.squeeze(model.predict_on_batch(training_data['inputs'])), np.squeeze(training_data['targets']))\n",
    "plt.xlabel('outputs')\n",
    "plt.ylabel('targets')\n",
    "plt.show()\n",
    "\n",
    "# Voila - what you see should be exactly the same as in the previous notebook!\n",
    "# You probably don't see the point of TensorFlow now - it took us the same number of lines of code\n",
    "# to achieve this simple result. However, once we go deeper in the next chapter,\n",
    "# TensorFlow will save us hundreds of lines of code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
